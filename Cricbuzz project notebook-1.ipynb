{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fd29378-3d76-4aba-b2d1-8f7372eae6e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pip uninstall azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df29bb0-57bb-47dc-ab60-8b962300af8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14471c78-debb-49d7-9c90-f3763eb2a0df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff95446d-7105-4c36-9e78-6a1e37a9a510",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython() # Run again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74633122-f71e-471b-9323-a3608c4e7e0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read and write the files in Blob Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78c153ea-3483-4a61-8915-0fb9f39b708c",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, udf\n",
    "# from pyspark.sql.types import StringType\n",
    "# import requests\n",
    "# import os\n",
    "# import requests\n",
    "# import json\n",
    "# from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
    "\n",
    "# # Your Azure Storage account information\n",
    "# azure_storage_connection_string = \"\"\n",
    "# container_name = \"cricbuzz-bronze\"  # The name of your container in Azure Blob Storage\n",
    "\n",
    "# # Create a connection to your Azure Blob Storage account\n",
    "# blob_service_client = BlobServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "# container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# url = \"https://api.cricapi.com/v1/cricScore?apikey=bba6abde-57fe-44c3-851b-5017bff34b03\"\n",
    "# payload = {}\n",
    "# headers = {}\n",
    "# response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# data = response.text\n",
    "# data = json.loads(data)\n",
    "\n",
    "# # Separate the data based on the \"ms\" field\n",
    "# live_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"live\"]\n",
    "# fixture_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"fixture\"]\n",
    "# result_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"result\"]\n",
    "\n",
    "# # Serialize the lists to JSON\n",
    "# live_matches_json = json.dumps(live_matches)\n",
    "# fixture_matches_json = json.dumps(fixture_matches)\n",
    "# result_matches_json = json.dumps(result_matches)\n",
    "\n",
    "# # Upload the JSON data to Azure Blob Storage\n",
    "# live_blob_client = container_client.get_blob_client(\"live_matches.json\")\n",
    "# fixture_blob_client = container_client.get_blob_client(\"fixture_matches.json\")\n",
    "# result_blob_client = container_client.get_blob_client(\"result_matches.json\")\n",
    "\n",
    "# live_blob_client.upload_blob(live_matches_json, overwrite=False, content_settings=ContentSettings(content_type='application/json'))\n",
    "# fixture_blob_client.upload_blob(fixture_matches_json, overwrite=False, content_settings=ContentSettings(content_type='application/json'))\n",
    "# result_blob_client.upload_blob(result_matches_json, overwrite=False, content_settings=ContentSettings(content_type='application/json'))\n",
    "\n",
    "# print(\"JSON data uploaded to Azure Blob Storage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "782148ab-29a5-441d-b014-2a71b05269ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Append the latest data in the existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b97c94b9-405c-4db0-bc47-c32ce33c5cab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, udf\n",
    "# from pyspark.sql.types import StringType\n",
    "# import requests\n",
    "# import os\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Your Azure Storage account information\n",
    "# azure_storage_connection_string = \"\"\n",
    "# container_name = \"cricbuzz-bronze\"\n",
    "\n",
    "# # Create a connection to your Azure Blob Storage account\n",
    "# blob_service_client = BlobServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "# container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# # Getting the  API \n",
    "# url = \"https://api.cricapi.com/v1/cricScore?apikey=bba6abde-57fe-44c3-851b-5017bff34b03\"\n",
    "# payload = {}\n",
    "# headers = {}\n",
    "# response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# data = response.text\n",
    "# data = json.loads(data)\n",
    "\n",
    "\n",
    "# # Name of the blob you want to append data to\n",
    "# blob_name = \"cricbuzz-bronze/full_data.json\"\n",
    "\n",
    "# # Load the existing data from the blob, if it exists\n",
    "# try:\n",
    "#     existing_blob_client = container_client.get_blob_client(blob_name)\n",
    "#     existing_data = existing_blob_client.download_blob().readall()\n",
    "#     existing_data = existing_data.decode(\"utf-8\")\n",
    "#     existing_matches = json.loads(existing_data)\n",
    "# except:\n",
    "#     # If the blob does not exist, initialize it with an empty list\n",
    "#     existing_matches = []\n",
    "\n",
    "# # Separate the new data based on the \"ms\" field\n",
    "# new_live_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"live\"]\n",
    "# new_fixture_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"fixture\"]\n",
    "# new_result_matches = [match for match in data[\"data\"] if match[\"ms\"] == \"result\"]\n",
    "\n",
    "# # Append the new data to the existing data\n",
    "# existing_matches.extend(new_live_matches)\n",
    "# existing_matches.extend(new_fixture_matches)\n",
    "# existing_matches.extend(new_result_matches)\n",
    "\n",
    "# # Serialize the combined data to JSON\n",
    "# combined_json = json.dumps(existing_matches)\n",
    "\n",
    "# # Upload the combined JSON data back to the blob\n",
    "# existing_blob_client.upload_blob(combined_json, overwrite=True, content_settings=ContentSettings(content_type='application/json'))\n",
    "\n",
    "# print(\"New data appended to the Azure Blob Storage blob.\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------2nd method---------------------------------------------------------\n",
    "\n",
    "\n",
    "# from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, udf\n",
    "# from pyspark.sql.types import StringType\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Your Azure Storage account information\n",
    "# azure_storage_connection_string = \"\"\n",
    "# container_name = \"cricbuzz-bronze\"\n",
    "\n",
    "# # Create a connection to your Azure Blob Storage account\n",
    "# blob_service_client = BlobServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "# container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# # Getting the API\n",
    "# url = \"https://api.cricapi.com/v1/cricScore?apikey=bba6abde-57fe-44c3-851b-5017bff34b03\"\n",
    "# payload = {}\n",
    "# headers = {}\n",
    "# response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# data = response.text\n",
    "# data = json.loads(data)\n",
    "\n",
    "# # Name of the blob you want to append data to\n",
    "# blob_name = \"cricbuzz-bronze/full_data1.json\"\n",
    "\n",
    "# # Check if the blob exists, and if it does, retrieve its content\n",
    "# if container_client.get_blob_client(blob_name).exists():\n",
    "#     # Retrieve the existing JSON data from the blob\n",
    "#     existing_blob_data = container_client.get_blob_client(blob_name).download_blob()\n",
    "#     existing_data = json.loads(existing_blob_data.readall())\n",
    "\n",
    "#     # Append the new data to the existing data\n",
    "#     existing_data[\"data\"].append(data[\"data\"])\n",
    "\n",
    "#     # Serialize the updated data to JSON\n",
    "#     updated_json_data = json.dumps(existing_data)\n",
    "\n",
    "#     # Upload the updated JSON data to the blob, overwriting the existing data\n",
    "#     blob_client = container_client.get_blob_client(blob_name)\n",
    "#     blob_client.upload_blob(updated_json_data, overwrite=True, content_settings=ContentSettings(content_type='application/json'))\n",
    "\n",
    "#     print(\"Data has been appended to the Azure Blob Storage blob.\")\n",
    "# else:\n",
    "#     # If the blob doesn't exist, create a new one with the new data\n",
    "#     new_json_data = json.dumps(data[\"data\"])\n",
    "#     blob_client = container_client.get_blob_client(blob_name)\n",
    "#     blob_client.upload_blob(new_json_data, overwrite=True, content_settings=ContentSettings(content_type='application/json'))\n",
    "\n",
    "#     print(\"Data has been uploaded to a new Azure Blob Storage blob.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09569c62-2182-4c73-a6d7-2a2536510162",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overwrite the latest data in the existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a9b40bd-d30a-4d14-9a4d-77f774c0ef98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1188308785938906>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mazure\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstorage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mblob\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col, udf\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'azure.storage'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\nFile \u001B[0;32m<command-1188308785938906>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mazure\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstorage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mblob\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col, udf\n\n\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'azure.storage'",
       "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'azure.storage'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Your Azure Storage account information\n",
    "azure_storage_connection_string = \"\"\n",
    "container_name = \"cricbuzz-bronze\"\n",
    "\n",
    "# Create a connection to your Azure Blob Storage account\n",
    "blob_service_client = BlobServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Getting the API \n",
    "url = \"https://api.cricapi.com/v1/cricScore?apikey=bba6abde-57fe-44c3-851b-5017bff34b03\"\n",
    "payload = {}\n",
    "headers = {}\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "data = response.text\n",
    "data = json.loads(data)\n",
    "\n",
    "# Name of the blob you want to overwrite data\n",
    "blob_name = \"cricbuzz-bronze/full_data1.json\"\n",
    "\n",
    "# Serialize the new data to JSON\n",
    "new_json_data = json.dumps(data[\"data\"])\n",
    "\n",
    "# Upload the new JSON data to the blob, overwriting the existing data\n",
    "blob_client = container_client.get_blob_client(blob_name)\n",
    "blob_client.upload_blob(new_json_data, overwrite=True, content_settings=ContentSettings(content_type='application/json'))\n",
    "\n",
    "print(\"Data in the Azure Blob Storage blob has been overwritten.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a98e6fe1-f5fa-43c7-84d3-2efaaa01dd9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94c944fd-3c04-47b0-8dd5-a045efcc6746",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, ContentSettings\n",
    "\n",
    "- ##### BlobServiceClient: \n",
    " to access Azure Blob Storage and read and write data to Azure Blob Storage.\n",
    "- ##### BlobClient:\n",
    " to interact with Azure Blob Storage. It provides operations to upload, download, and delete.    \n",
    "- ##### ContainerClient:\n",
    " allows you to create, access, and manipulate Azure Blob Storage containers.\n",
    "- ##### ContentSettings:\n",
    " to specify the content type, encoding, and other properties of a blob when uploading or downloading it from Azure Blob Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a92e8bfc-09c0-4048-9255-a449c9afa50d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Upload blob to Azure\n",
    "\n",
    "- (content_type='application/json') --> uploading a new JSON blob to Azure Blob Storage, so you need to specify the content type as application/json.\n",
    "\n",
    "##### Here is a list of some common MIME content types:\n",
    "\n",
    "- application/json: JSON data\n",
    "- text/plain: Plain text\n",
    "- image/jpeg: JPEG image\n",
    "- image/png: PNG image\n",
    "- video/mp4: MP4 video"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cricbuzz project notebook-1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
